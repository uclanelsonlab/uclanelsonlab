---
layout: post
title: LLMs for Paper Writing
category: newblog
tags:
    - prose
    - ai
    - deep-learning
    - llm
    - scientific-publishing
header-img: images/post/llm4papersschematic.png
---

*by: [Jordan Matelsky](https://jordan.matelsky.com)*

Much has been said about [AI language models' role in scientific publishing](https://www.scientificamerican.com/article/chatbots-have-thoroughly-infiltrated-scientific-publishing/) (see also [_Mapping the Increasing Use of LLMs in Scientific Papers_](https://arxiv.org/abs/2404.01268)) and [the implications of AI authorship more generally](https://houstonlawreview.org/article/92132-what-is-an-author-copyright-authorship-of-ai-art-through-a-philosophical-lens), but it is undeniable that LLM assistance — used properly — can be a force-multiplier for technical writing.

Collaborative editors like Google Docs or [Overleaf](https://www.overleaf.com/) have made it easier to write papers with human coauthors, and these tools have already acquainted us with the workflows of asynchronous text collaboration. Early in 2023, our team ([me](https://jordan.matelsky.com/), and Drs. [Richard Lange](https://sites.google.com/view/bonsai-lab/home), [Konrad Kording](https://kordinglab.com/)) cobbled together a simple tool to use a language model to asynchronously edit a paper in the Overleaf editor — the industry standard collaborative editor for LaTeX documents. Today we are [open-sourcing this project](https://github.com/KordingLab/llm4papers) so that others can adapt and adopt it for their scientific writing workflows as well.

![Schematic]({{site.url}}/images/post/llm4papersschematic.png)

## Technical approach

Though Overleaf does not have a public-facing editing API, they have a robust git-flavored backend that allows for programmatic editing of documents. We built a simple Python tool to listen for changes to this git repository, and when a change is detected, the tool sends the new text to a language model of your choice. (We've been using the OpenAI API for this purpose, but any language model API can be used — including local on-prem models).

Because this tool works at the backend git level, it can be used with any git repository, not just Overleaf. We've tested it with GitHub repositories (and plaintext files!) as well, and it works just as well there. (We encourage engineers to check out our [`PaperRemote`](https://github.com/KordingLab/llm4papers/tree/main/llm4papers/paper_remote) abstraction if you want to add support for another editor!) Talking to the backend (rather than implementing this through, say, a browser extension) also means that end users don't need to install anything. The tool can be run on a server, and the end user can simply use Overleaf as they normally would.

## Limitations

As a result of interfacing with git — a tool designed for version control, not real-time collaboration — we had to make some compromises. This library implements its own debouncing and ["clobber-avoidance"](https://github.com/KordingLab/llm4papers/blob/7d54b9839cc803857151be56f4a7eeeb9ba0d7a3/llm4papers/paper_remote/OverleafGitPaperRemote.py#L50) to prevent the model from editing too close to ongoing changes from human collaborators. This means that the model will not edit the document until it has been stable for a few seconds, or until the human collaborator has moved on to a new section. (In our testing, this was not a significant limitation, since it's rare that you want AI editing the same text you're typing.)

We also have chosen to use LaTeX comments (text starting with `% @ai:`) to trigger the AI model, rather than having the model edit the entire document. This allows for fine-grained control over the AI's edits, and allows for human collaborators to easily see where the AI has made changes. But naturally, we expect users will want to use the same comment-style task assignment commonly used in Overleaf and other editors like Google Docs, and we believe that this is a natural extension of our tool. But we haven't figured out how to get programmatic access to Overleaf comments yet... maybe you know what to do? :)

## Upshots

Naturally, AI has some very well-known (and some not-well-known) failures and limitations. Hallucination and plagiarism are two of the most common, and we've found that the best way to avoid these is to use the AI as an editorial tool, not as a replacement for human thought. And because AI is only as good as its training data, you should never expect AI to understand the logic or overarching themes of your paper, nor should you use it for literature reviews or in lieu of human oversight.

Nonetheless, we've found that using LLMs for paper writing has been a boon to our productivity. The AI can help with things like equation formatting, spelling, or rephrasing complex ideas. We've found that AI prompted with [good paper-writing techniques](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005619) can be particularly good at annoying but simple tasks, like rephrasing sentences, reformatting text, checking for text flow, or making suggestions about readability and clarity.

We encourage the open source community to take advantage of this tool and — if you're inspired — to collaborate with us by steering its development. We're excited to see how this tool and AI tools like it can make the scientific process more efficient and more accessible to all!

---

* Jordan Matelsky
* Dr. Richard Lange
* Dr. Konrad Kording
